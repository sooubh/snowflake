# ðŸ—„ï¸ Database Schema & Snowflake

## â„ï¸ Snowflake Configuration

StockHealth AI relies on a specific Snowflake schema structure to function. The data is modeled to represent a multi-tenant environment (where "tenants" are the different stores) within a single unified table structure for analytics.

### Connection Parameters
The application connects using standard Snowflake parameters defined in `.env.local`:
*   `SNOWFLAKE_ACCOUNT`: Unique account identifier.
*   `SNOWFLAKE_USER`: Service account user.
*   `SNOWFLAKE_ROLE`: Role with R/W access to the schema (and `CORTEX_USER` role).

---

## ðŸ“‹ Tables

### 1. `ITEMS` (Main Inventory Table)
Stores the current state of every single item in the network.

| Column | Type | Description |
| :--- | :--- | :--- |
| `ID` | `VARCHAR` | Unique string ID for the item. |
| `NAME` | `VARCHAR` | Display name (e.g., "Paracetamol 500mg"). |
| `CATEGORY` | `VARCHAR` | Grouping (Medicine, Grains, Shelter). |
| `QUANTITY` | `NUMBER` | Current stock count. |
| `PRICE` | `FLOAT` | Unit price. |
| `UNIT` | `VARCHAR` | Unit of measure (Kg, Box, Strip). |
| `STATUS` | `VARCHAR` | 'In Stock', 'Low Stock', 'Out of Stock'. |
| `OWNER_ID` | `VARCHAR` | ID of the Store that owns this item (e.g., `hosp-r1`). |
| `SECTION` | `VARCHAR` | 'FDC', 'Hospital', or 'NGO'. Used for segregation. |
| `LAST_UPDATED` | `TIMESTAMP` | Time of last modification. |
| `MIN_QUANTITY` | `NUMBER` | Threshold for low-stock alerts. |
| `EXPIRY_DATE` | `TIMESTAMP` | Impactful date for perishables. |
| `DESCRIPTION` | `VARCHAR` | Extended text details. |

### 2. `PURCHASE_ORDERS`
Tracks procurement requests generated by users or the AI agent.

| Column | Type | Description |
| :--- | :--- | :--- |
| `ID` | `VARCHAR` | Unique PO ID. |
| `ITEM_ID` | `VARCHAR` | Link to the relevant Item. |
| `ITEM_NAME` | `VARCHAR` | Snapshot of item name. |
| `QUANTITY` | `NUMBER` | Requested quantity. |
| `STATUS` | `VARCHAR` | 'Pending', 'Approved', 'Rejected'. |
| `CREATED_AT` | `TIMESTAMP` | Creation time. |

---

## ðŸ¤– Cortex AI Integration

### How It Works
We do not use an external vector database. Instead, we use Snowflake's ability to run inference directly on the data.

1.  **Context Construction**: When an AI query is made, we fetch a relevant subset of the `ITEMS` table (filtered by the user's Store ID) and format it as a JSON string.
2.  **Prompt Engineering**: We wrap this data in a strict System Prompt:
    > "You are an inventory assistant. Here is the current stock data: [JSON_DATA]. Answer the user's question: [USER_QUERY]. Return response in JSON format."
3.  **Execution**: We pass this entire block to `SNOWFLAKE.CORTEX.COMPLETE('llama3-70b', <prompt>)`.
4.  **Result**: The SQL function returns the AI's generated response, which we parse and display.

### Advantages
*   **Security**: Data never leaves the Snowflake perimeter.
*   **Freshness**: The AI always sees the exact real-time state of the database, not an outdated embedding.
*   **Simplicity**: No need to manage Pinecone/Weaviate or separate embedding pipelines.
